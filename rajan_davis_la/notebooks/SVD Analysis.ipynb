{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "# borrowed from http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = pd.read_json(\"../data_fetching/json2/SequelMemes.json\")\n",
    "pm = pd.read_json(\"../data_fetching/json2/PrequelMemes.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                title  is_sequel_meme\n",
      "0                      Drunk Politics               0\n",
      "1                 When the Fun Begins               0\n",
      "2                      Just one Windu               0\n",
      "3  dlmoisttlotjidnftdsaydihbpjfastmne               0\n",
      "4                     Drunk Democracy               0\n",
      "                                                   title  is_sequel_meme\n",
      "14595                        His swoleness got him #6!!!               1\n",
      "14596  Looks like someone at my local brewery is a Se...               1\n",
      "14597  MAGA.... Nah! Time to make the Republic great ...               1\n",
      "14598           Take On Me except it's Leia slapping Poe               1\n",
      "14599           Take On Me except it's Leia slapping Poe               1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "sm_titles = sm[[\"title\"]]\n",
    "pm_titles = pm[[\"title\"]]\n",
    "\n",
    "sm_titles[\"is_sequel_meme\"] = 1\n",
    "pm_titles[\"is_sequel_meme\"] = 0\n",
    "\n",
    "meme_titles = pd.concat([pm_titles,sm_titles])\n",
    "print(meme_titles.head())\n",
    "print(meme_titles.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [title[0] for title in meme_titles[[\"title\"]].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed from http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting tfidf\n",
      "Scores for tfidf using bnb Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 0.6624694786230669\n",
      "BernoulliNB(alpha=0.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "{'alpha': 0.0}\n",
      "Test data: 0.6313370673560247\n",
      "BernoulliNB(alpha=0.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "{'alpha': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "Fitting tfidf__max_df_of_0.25\n",
      "Scores for tfidf__max_df_of_0.25 using bnb Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 0.6540431847560684\n",
      "BernoulliNB(alpha=0.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "{'alpha': 0.0}\n",
      "Test data: 0.6218583943702427\n",
      "BernoulliNB(alpha=0.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "{'alpha': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "Fitting tfidf__n_gram_range_of_(1, 1)\n",
      "Scores for tfidf__n_gram_range_of_(1, 1) using bnb Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 0.6555273615167329\n",
      "BernoulliNB(alpha=0.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "{'alpha': 0.0}\n",
      "Test data: 0.6293264397529801\n",
      "BernoulliNB(alpha=0.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "{'alpha': 0.0}\n",
      "\n",
      "\n",
      "\n",
      "Fitting tfidf__n_gram_range_of_(1, 1)_max_df_of0.25\n",
      "Scores for tfidf__n_gram_range_of_(1, 1)_max_df_of0.25 using bnb Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 0.6496385311437737\n",
      "BernoulliNB(alpha=0.4444444444444444, binarize=0.0, class_prior=None,\n",
      "      fit_prior=True)\n",
      "{'alpha': 0.4444444444444444}\n",
      "Test data: 0.634496625017952\n",
      "BernoulliNB(alpha=0.4444444444444444, binarize=0.0, class_prior=None,\n",
      "      fit_prior=True)\n",
      "{'alpha': 0.4444444444444444}\n",
      "\n",
      "\n",
      "\n",
      "Fitting tfidf__n_gram_range_of_(1, 2)\n"
     ]
    }
   ],
   "source": [
    "vectorizers_start = {\n",
    "#     \"cvec\" : CountVectorizer,\n",
    "    \"tfidf\" : TfidfVectorizer,\n",
    "}\n",
    "\n",
    "vectorizers = {}\n",
    "\n",
    "for key,vec in vectorizers_start.items():\n",
    "    vectorizers[key] = vec(stop_words='english', tokenizer=LemmaTokenizer())\n",
    "    for max_df in (0.25, 0.5, 0.75):\n",
    "        vectorizers[f\"{key}__max_df_of_{max_df}\"] = vec(stop_words='english', max_df=max_df)\n",
    "        for n_gram_range in [(1, 1), (1, 2), (1, 3), (1, 4)]:\n",
    "            vectorizers[f\"{key}__n_gram_range_of_{n_gram_range}\"] = vec(stop_words='english', ngram_range=n_gram_range)\n",
    "            vectorizers[f\"{key}__n_gram_range_of_{n_gram_range}_max_df_of{max_df}\"] = vec(stop_words='english', ngram_range=n_gram_range, max_df=max_df)\n",
    "\n",
    "classifiers = {\n",
    "    \"bnb\" : BernoulliNB(), #=> Fast and good enough score\n",
    "#     \"mnb\" : MultinomialNB(), #=> Fast and good enough score\n",
    "#     \"logr\": LogisticRegression(), #=> Best score, but super slow\n",
    "#     \"knn\" : KNeighborsClassifier(), #=> Super overfit, not great scores\n",
    "#     \"tree\" : DecisionTreeClassifier(),\n",
    "#     \"rfc\" : RandomForestClassifier(), #=> Very overfit, not much better than Naive Bayes\n",
    "#     \"gbc\" : GradientBoostingClassifier(), #=> Not great, worse than Naive Bayes\n",
    "#     \"ada\" : AdaBoostClassifier(), #=> Not great, worse than Naive Bayes\n",
    "#     \"svm\" : SVC(), #=> painstakingly slow, couldn't run on my computer :/\n",
    "}\n",
    "\n",
    "# Borrowed from https://www.kaggle.com/mayu0116/hyper-parameters-tuning-of-dtree-rf-svm-knn\n",
    "# and https://optunity.readthedocs.io/en/stable/notebooks/notebooks/sklearn-automated-classification.html\n",
    "hyper_parameters = {\n",
    "    \"bnb\" : {\n",
    "        \"alpha\": np.linspace(0.0,1.0,10)\n",
    "    },\n",
    "    \"mnb\" : {\n",
    "        \"alpha\": np.linspace(0.0,1.0,10)\n",
    "    },\n",
    "    \"logr\": {\n",
    "        \"penalty\" : ['l1', 'l2'],\n",
    "        \"C\": np.logspace(0, 10, 20)\n",
    "    },\n",
    "    \"knn\" : {\n",
    "        'n_neighbors':[1,2,3,4,5],\n",
    "        'weights':['uniform', 'distance'],\n",
    "    },\n",
    "    \"svm\" : {\n",
    "        'kernel': ['linear', 'poly', 'rbf'],\n",
    "        'C': [1, 2, 10, 50],\n",
    "        'gamma': [0, 1],\n",
    "        'degree': [2, 5],\n",
    "        'coef0': [0, 1]\n",
    "    },\n",
    "    \"tree\": {\n",
    "        \n",
    "    },\n",
    "    \"rfc\":{\n",
    "        \n",
    "    },\n",
    "    \"gbc\":{\n",
    "        \"n_estimators\" : [50,100,150]\n",
    "    },\n",
    "    \"ada\":{\n",
    "        \"base_estimator\": [BernoulliNB(), MultinomialNB(), LogisticRegression()],\n",
    "        \"n_estimators\" : [50,100,150]\n",
    "    }\n",
    "}\n",
    "\n",
    "for key,val in vectorizers.items():\n",
    "    print(f\"Fitting {key}\")\n",
    "    val.fit(corpus)\n",
    "    # Transform the corpus\n",
    "    new_corpus  = val.transform(corpus)\n",
    "    sparse_df = pd.SparseDataFrame(new_corpus, columns=val.get_feature_names())\n",
    "    sparse_df.fillna(0, inplace=True)\n",
    "    SVD = TruncatedSVD(n_components=1000)\n",
    "    svd_matrix = SVD.fit_transform(sparse_df)\n",
    "    component_names = [\"component_\"+str(i+1) for i in range(1000)]\n",
    "    svd_df = pd.DataFrame(svd_matrix,\n",
    "                      columns=component_names)\n",
    "    \n",
    "    y = meme_titles[[\"is_sequel_meme\"]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(svd_df, y)\n",
    "    for class_key, classifier in classifiers.items():\n",
    "        print(f\"Scores for {key} using {class_key} Classifier\")\n",
    "        gs = GridSearchCV(classifier, param_grid=hyper_parameters[class_key], n_jobs=-1);\n",
    "        gs.fit(X_train,y_train);\n",
    "        print(f\"Train data: {gs.score(X_train, y_train)}\")\n",
    "        print(f\"{gs.best_estimator_}\")\n",
    "        print(f\"{gs.best_params_}\")\n",
    "        print(f\"Test data: {gs.score(X_test, y_test)}\")\n",
    "        print(f\"{gs.best_estimator_}\")\n",
    "        print(f\"{gs.best_params_}\")\n",
    "        [print() for i in range(0,3)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
